{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNB:\n",
    "    '''\n",
    "    fit函数输入参数：\n",
    "        X 测试数据集\n",
    "        y 标记数据\n",
    "        alpha 贝叶斯估计的正数λ\n",
    "    predict函数输入参数：\n",
    "        test 测试数据集\n",
    "    '''\n",
    "    def fit(self, X, y, alpha = 0):\n",
    "        # 整理分类\n",
    "        feature_data = defaultdict(lambda: [])\n",
    "        label_data = defaultdict(lambda: 0)\n",
    "        for feature, lab in zip(X, y):\n",
    "            feature_data[lab].append(feature)\n",
    "            label_data[lab] += 1\n",
    "\n",
    "        # 计算先验概率\n",
    "        self.label = y\n",
    "        self.pri_p_label = {k: (v + alpha)/(len(self.label) + len(np.unique(self.label)) * alpha) for k,v in label_data.items()}\n",
    "        \n",
    "        # 计算不同特征值的条件概率\n",
    "        self.cond_p_feature = defaultdict(lambda: {})\n",
    "        for i,sub in feature_data.items():\n",
    "            sub = np.array(sub)\n",
    "            for f_dim in range(sub.shape[1]):\n",
    "                for feature in np.unique(X[:,f_dim]):\n",
    "                    self.cond_p_feature[i][(f_dim,feature)] = (np.sum(sub[:,f_dim] == feature) + alpha) / (sub.shape[0] + len(np.unique(X[:,f_dim])) * alpha)\n",
    "                    \n",
    "    def predict(self, test):\n",
    "        p_data = {}\n",
    "        for sub_label in np.unique(self.label):\n",
    "            # 对概率值取log，防止乘积时浮点下溢\n",
    "            p_data[sub_label] = self.pri_p_label[sub_label]\n",
    "            for i in range(len(test)):\n",
    "                if self.cond_p_feature[sub_label].get((i,test[i])):\n",
    "                    p_data[sub_label] *= self.cond_p_feature[sub_label][(i,test[i])]\n",
    "        opt_label = max(p_data, key = p_data.get)\n",
    "        return([opt_label, p_data.get(opt_label)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后使用上述算法来预测下数字识别的数据集，计算测试错误率，这里将数据集分割成80%的训练集和20%的测试集，并将非0值替换成1（其实这样来看应该用朴素贝叶斯的伯努利模型，但是先多项式模型用着吧）\n",
    "\n",
    "### 训练集\n",
    "\n",
    "数据集使用：MNIST（数字识别）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"train.csv\")\n",
    "dataset = np.array(dataset)\n",
    "dataset[:,1:][dataset[:,1:] != 0] = 1\n",
    "label = dataset[:,0]\n",
    "# 分割训练集和测试集\n",
    "train_dat, test_dat, train_label, test_label = train_test_split(dataset[:,1:], label, test_size = 0.2, random_state = 123456)\n",
    "# 构建NB模型\n",
    "model = MultinomialNB()\n",
    "model.fit(X=train_dat, y=train_label, alpha=1)\n",
    "# 使用NB模型进行预测\n",
    "pl = {}\n",
    "i = 0\n",
    "for test in test_dat:\n",
    "    temp = model.predict(test=test)\n",
    "    pl[i] = temp\n",
    "    i += 1\n",
    "# 输出测试错误率%\n",
    "error = 0\n",
    "for k,v in pl.items():\n",
    "    if test_label[k] != v[0]:\n",
    "        error += 1\n",
    "print(error/len(test_label)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
